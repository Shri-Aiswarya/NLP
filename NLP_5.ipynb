{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl4VGWUpla91gG95WhXw1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shri-Aiswarya/NLP/blob/main/NLP_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1.\n",
        "Text Summary\n",
        "\n",
        "• Use the ‘spaceX_DP.txt’ file in DATA 690 Data Files.\n",
        "\n",
        "• Import 'spacy' for stopwords and 'string' for punctuation.\n",
        "\n",
        "• Tokenize the 'SpaceX.txt' corpus.\n",
        "\n",
        "• Build 'word frequency'. Make sure you have removed the stopwords.\n",
        "\n",
        "• Determine the maximum frequency as 'word_frequencies[word]=\n",
        "(word_frequencies[word]/maximum_frequency).\n",
        "\n",
        "• Tokenize the sentences. Generate the sentence_scores. Score every sentence based on number of words.\n",
        "\n",
        "• Import nlargest from heapq and provide 'summarized_sentences'.\n",
        "\n",
        "• Convert sentences from spacy to strings and join all sentences.\n",
        "\n",
        "• Provide a summary once you have converted spacy outputs to strings.\n",
        "\n",
        "• Determine the length of the summary.\n",
        "\n",
        "• Determine the length of the original text.\n",
        "\n",
        "• Use spacy and textrank to summarize the text.\n",
        "\n",
        "• Print the summary in 5 sentences."
      ],
      "metadata": {
        "id": "SNMilmndLzRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "from heapq import nlargest\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "\n",
        "#Downloading necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "#Loading the SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#Loading the downloaded text file\n",
        "with open('spaceX_DP.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#Summarization\n",
        "doc = nlp(text)\n",
        "\n",
        "#Removing the stopwords and punctuation, and building word frequencies\n",
        "stopwords = nlp.Defaults.stop_words\n",
        "word_frequencies = Counter()\n",
        "\n",
        "for token in doc:\n",
        "    if token.text.lower() not in stopwords and token.text not in punctuation:\n",
        "        word_frequencies[token.text.lower()] += 1\n",
        "\n",
        "#Calculating the maximum frequency\n",
        "maximum_frequency = max(word_frequencies.values())\n",
        "word_frequencies = {word: freq / maximum_frequency for word, freq in word_frequencies.items()}\n",
        "\n",
        "#Tokenizing sentences and generating sentence_scores\n",
        "for sent in doc.sents:\n",
        "    for word in sent:\n",
        "        if word.text.lower() in word_frequencies:\n",
        "            if sent not in sentence_scores:\n",
        "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "            else:\n",
        "                sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
        "\n",
        "#Getting the top 5 sentences in the summary\n",
        "if sentence_scores:\n",
        "    summarized_sentences = nlargest(5, sentence_scores, key=sentence_scores.get)\n",
        "else:\n",
        "    summarized_sentences = []\n",
        "\n",
        "#Converting sentences from spacy to strings and joining all sentences\n",
        "summary = ' '.join([str(sentence) for sentence in summarized_sentences])\n",
        "\n",
        "#Lengths of the summary and original text\n",
        "summary_length = len(summary.split())\n",
        "original_length = len(text.split())\n",
        "\n",
        "\n",
        "#Sentiment Analysis\n",
        "blob = TextBlob(text)\n",
        "\n",
        "#Getting sentiment metrics\n",
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "#Determining polarity\n",
        "if polarity > 0:\n",
        "    sentiment = \"Positive\"\n",
        "elif polarity < 0:\n",
        "    sentiment = \"Negative\"\n",
        "else:\n",
        "    sentiment = \"Neutral\"\n",
        "\n",
        "#Printing the sentiment results\n",
        "print(f\"\\nOverall Sentiment: {sentiment}\")\n",
        "print(f\"Polarity (Compound): {polarity}\")\n",
        "print(f\"Subjectivity: {subjectivity}\")\n",
        "\n",
        "#Determining if the text is more subjective or objective\n",
        "if subjectivity > 0.5:\n",
        "    print(\"The text is more subjective.\")\n",
        "else:\n",
        "    print(\"The text is more objective.\")\n",
        "\n",
        "#Printing the summary and lengths\n",
        "print(\"\\nSummary:\")\n",
        "print(summary)\n",
        "print(\"\\nLength of the summary:\", summary_length)\n",
        "print(\"Length of the original text:\", original_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFcc01EqUGBc",
        "outputId": "96633686-a1c3-4b38-f94f-8a4855d8f118"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Overall Sentiment: Positive\n",
            "Polarity (Compound): 0.07778410274128203\n",
            "Subjectivity: 0.4412223159089057\n",
            "The text is more objective.\n",
            "\n",
            "Summary:\n",
            "However, the regulatory agency that is was supposed to be guiding this environmental impact process, the FAA, allowed SpaceX.”Five years after the FAA issued its Final Environmental Impact Statement, the agency issued a 23-page “Written Re-Evaluation of the 2014 Final Environmental Impact Statement for the SpaceX Texas Launch Site,” on May 21, 2019, that acknowledged SpaceX had switched from the Falcon program to the Starship project that included a new “experimental test program.” However, the regulatory agency that is was supposed to be guiding this environmental impact process, the FAA, allowed SpaceX.”Five years after the FAA issued its Final Environmental Impact Statement, the agency issued a 23-page “Written Re-Evaluation of the 2014 Final Environmental Impact Statement for the SpaceX Texas Launch Site,” on May 21, 2019, that acknowledged SpaceX had switched from the Falcon program to the Starship project that included a new “experimental test program.” However, the regulatory agency that is was supposed to be guiding this environmental impact process, the FAA, allowed SpaceX.”Five years after the FAA issued its Final Environmental Impact Statement, the agency issued a 23-page “Written Re-Evaluation of the 2014 Final Environmental Impact Statement for the SpaceX Texas Launch Site,” on May 21, 2019, that acknowledged SpaceX had switched from the Falcon program to the Starship project that included a new “experimental test program.” However, the regulatory agency that is was supposed to be guiding this environmental impact process, the FAA, allowed SpaceX.”Five years after the FAA issued its Final Environmental Impact Statement, the agency issued a 23-page “Written Re-Evaluation of the 2014 Final Environmental Impact Statement for the SpaceX Texas Launch Site,” on May 21, 2019, that acknowledged SpaceX had switched from the Falcon program to the Starship project that included a new “experimental test program.” However, the regulatory agency that is was supposed to be guiding this environmental impact process, the FAA, allowed SpaceX.”Five years after the FAA issued its Final Environmental Impact Statement, the agency issued a 23-page “Written Re-Evaluation of the 2014 Final Environmental Impact Statement for the SpaceX Texas Launch Site,” on May 21, 2019, that acknowledged SpaceX had switched from the Falcon program to the Starship project that included a new “experimental test program.”\n",
            "\n",
            "Length of the summary: 365\n",
            "Length of the original text: 20204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2.\n",
        "Sentiment Analysis\n",
        "\n",
        "What is the overall sentiment of the ‘spaceX.txt’ text?\n",
        "\n",
        "Provide the compound, negative,\n",
        "neutral, and positive metrics. Is the text more ‘subjective’ or more ‘objective’?"
      ],
      "metadata": {
        "id": "D4ItVnJKUMR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "\n",
        "# Downloading the necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "#Loading the downloaded text file\n",
        "with open('spaceX_DP.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#Creating the TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "#Getting the sentiment metrics\n",
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "#Determining polarity\n",
        "if polarity > 0:\n",
        "    sentiment = \"Positive\"\n",
        "elif polarity < 0:\n",
        "    sentiment = \"Negative\"\n",
        "else:\n",
        "    sentiment = \"Neutral\"\n",
        "\n",
        "#Printing the results\n",
        "print(f\"Overall Sentiment: {sentiment}\")\n",
        "print(f\"Polarity (Compound): {polarity}\")\n",
        "print(f\"Subjectivity: {subjectivity}\")\n",
        "\n",
        "# Determine if the text is more subjective or objective\n",
        "if subjectivity > 0.5:\n",
        "    print(\"The text is more subjective.\")\n",
        "else:\n",
        "    print(\"The text is more objective.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8qYJ8UHUWH2",
        "outputId": "0bf1108a-0e5c-41ab-8215-d98dd86de8b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Sentiment: Positive\n",
            "Polarity (Compound): 0.07778410274128203\n",
            "Subjectivity: 0.4412223159089057\n",
            "The text is more objective.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}