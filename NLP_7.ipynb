{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYwKNvYErh/FRdWU8AMMVK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shri-Aiswarya/NLP/blob/main/NLP_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1. Sentiment Analysis\n",
        "\n",
        "• Using textblob, what is the probability that the sentiment in the\n",
        "Burbank text is going to negative?"
      ],
      "metadata": {
        "id": "SEIZLd0ywLxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploading the file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#Reading the data from the text file\n",
        "filename = 'Burbank.txt'\n",
        "with open(filename, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#Analyzing sentiment using TextBlob\n",
        "from textblob import TextBlob\n",
        "\n",
        "#Creating a TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "#Getting the sentiment polarity\n",
        "polarity = blob.sentiment.polarity\n",
        "\n",
        "#Determining if the sentiment is negative\n",
        "if polarity < 0:\n",
        "    sentiment = \"negative\"\n",
        "elif polarity == 0:\n",
        "    sentiment = \"neutral\"\n",
        "else:\n",
        "    sentiment = \"positive\"\n",
        "\n",
        "#Printing the results\n",
        "print(f\"Polarity: {polarity}, Sentiment: {sentiment}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "q116jOUAkh3l",
        "outputId": "0359d7e6-6823-4f0e-a054-26f15e72910e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3c8ac3c-0f98-47d6-bf6d-7daf6efed16d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b3c8ac3c-0f98-47d6-bf6d-7daf6efed16d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Burbank.txt to Burbank.txt\n",
            "Polarity: 0.09869334480780263, Sentiment: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2. Sentiment Analysis\n",
        "\n",
        "• Using the data from exercise 1 and textblob, what is the overall\n",
        "sentiment and subjectivity?"
      ],
      "metadata": {
        "id": "hSpfmhqElBaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Uploading the file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#Reading the data from the uploaded text file\n",
        "filename = 'Burbank.txt'  # Change this to your actual filename\n",
        "with open(filename, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#Analyzing sentiment using TextBlob\n",
        "from textblob import TextBlob\n",
        "\n",
        "#Creating a TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "#Getting overall sentiment polarity and subjectivity\n",
        "polarity = blob.sentiment.polarity\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "\n",
        "#Determining sentiment category\n",
        "if polarity < 0:\n",
        "    sentiment = \"negative\"\n",
        "elif polarity == 0:\n",
        "    sentiment = \"neutral\"\n",
        "else:\n",
        "    sentiment = \"positive\"\n",
        "\n",
        "#Printing the results\n",
        "print(f\"Overall Polarity: {polarity}, Sentiment: {sentiment}\")\n",
        "print(f\"Overall Subjectivity: {subjectivity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "uo9uR-EflilF",
        "outputId": "938374a8-c1b0-4d02-d094-96321c206f45"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a8cb72b0-4648-436e-bff3-257d5fef1a70\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a8cb72b0-4648-436e-bff3-257d5fef1a70\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Burbank.txt to Burbank (3).txt\n",
            "Overall Polarity: 0.09869334480780263, Sentiment: positive\n",
            "Overall Subjectivity: 0.3790877796901893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3.\n",
        "\n",
        "Key topic using ‘Word’ from textblob (very simple way to\n",
        "determine the key topics) based on the Burbank text file.\n",
        "\n",
        "• Import Word from textblob. Identify the key topics by using Word from textblob."
      ],
      "metadata": {
        "id": "mFTVL5Lnl6OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraries\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!python -m textblob.download_corpora\n",
        "\n",
        "#Uploading the file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "#Reading the data from the uploaded text file\n",
        "filename = 'Burbank.txt'  # Change this to your actual filename if needed\n",
        "with open(filename, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "#Analyzing key topics using TextBlob\n",
        "from textblob import TextBlob\n",
        "from collections import Counter\n",
        "\n",
        "#Creating a TextBlob object\n",
        "blob = TextBlob(text)\n",
        "\n",
        "#Extracting words and converting them to lowercase\n",
        "words = [word.lower() for word in blob.words]\n",
        "\n",
        "#Counting frequency of each word\n",
        "word_counts = Counter(words)\n",
        "\n",
        "#Getting the most common words as key topics\n",
        "key_topics = word_counts.most_common(10)  # Change the number for more topics\n",
        "\n",
        "#Printing the results\n",
        "print(\"Key Topics (Most Common Words):\")\n",
        "for word, count in key_topics:\n",
        "    print(f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "1mKRDAYzmA9n",
        "outputId": "7d50088e-cb54-490e-c8cc-a77d071b5762"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c597fea9-0720-48b9-9b33-1a9535c68179\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c597fea9-0720-48b9-9b33-1a9535c68179\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Burbank.txt to Burbank (5).txt\n",
            "Key Topics (Most Common Words):\n",
            "the: 114\n",
            "of: 50\n",
            "to: 39\n",
            "and: 36\n",
            "that: 21\n",
            "in: 20\n",
            "a: 18\n",
            "faa: 13\n",
            "burbank: 12\n",
            "said: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4. Sentiment analysis with spaCy.\n",
        "\n",
        "• Load the datasets ‘amazon_cells_labelled.txt’, ‘imdb_labelled.txt’,\n",
        "‘yelp_labelled.txt’\n",
        "\n",
        "• Create ‘combined_col’ by joining the tables such that\n",
        "combined_col=[data_amazon, data_imdb, data_yelp]\n",
        "\n",
        "• Check the structure of data_amazon\n",
        "\n",
        "• Add headers for columns in each dataset: ‘Review’ and ‘Label’\n",
        "\n",
        "• Create a “Company’ column to identify each company ‘Amazon’,\n",
        "‘imdb’, and ‘yelp’\n",
        "\n",
        "• Explore the structure of the new dataset called ‘comb_data’\n",
        "\n",
        "• Use ‘comb_data.to_csv’ to create the ‘Sentiment_Analysis_Dataset’\n",
        "\n",
        "• Print the columns\n",
        "\n",
        "• Check for null values\n",
        "\n",
        "• Import STOP_WORDS from spacy and stopwords from\n",
        "spacy.lang.en.stop_words\n",
        "\n",
        "• Build a list of stopwords for filtering\n",
        "\n",
        "• Import string, define ‘punctuations’ and define a ‘parser’\n",
        "\n",
        "• Tokenize the sentences\n",
        "\n",
        "• Import ‘CountVectorize’, ‘TfidVectorizer’, ‘accuracy_score’,\n",
        "‘TransformerMixin’, ‘Pipeline’, and ‘LinearSVC’\n",
        "\n",
        "• Create a class 'predictors(TransformerMixin)'. Within the class, define\n",
        "'transform', 'fit', and 'get_params'\n",
        "\n",
        "• Create a basic function to clean the text\n",
        "\n",
        "• Vectorize and use LinearSVC as a classifier\n",
        "\n",
        "• Use TfidfVectorizer\n",
        "\n",
        "• Split the ‘com_data’ dataset into a train and test (20%) set\n",
        "\n",
        "• Create a pipeline to clean, tokenize, vectorize, and classify as ‘pipe_countvect’\n",
        "\n",
        "• Fit the data\n",
        "\n",
        "• Predict with the test dataset\n",
        "\n",
        "• Prediction results as ‘1’ for positive reviews, and ‘0’ for negative reviews\n",
        "\n",
        "• Use print(sample, “Prediction➔”, pred)\n",
        "\n",
        "• Determine the accuracy for the test dataset, X_test/sample\n",
        "prediction, and train dataset"
      ],
      "metadata": {
        "id": "8HAbT57PnKb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the required libraries\n",
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import TransformerMixin\n",
        "import string\n",
        "from google.colab import files\n",
        "\n",
        "#Loading the datasets\n",
        "data_amazon = pd.read_csv('amazon_cells_labelled.txt', header=None, names=['Review', 'Label'], sep='\\t')\n",
        "data_imdb = pd.read_csv('imdb_labelled.txt', header=None, names=['Review', 'Label'], sep='\\t')\n",
        "data_yelp = pd.read_csv('yelp_labelled.txt', header=None, names=['Review', 'Label'], sep='\\t')\n",
        "\n",
        "#Adding 'Company' column\n",
        "data_amazon['Company'] = 'Amazon'\n",
        "data_imdb['Company'] = 'IMDB'\n",
        "data_yelp['Company'] = 'Yelp'\n",
        "\n",
        "#Combining datasets\n",
        "combined_col = pd.concat([data_amazon, data_imdb, data_yelp], ignore_index=True)\n",
        "\n",
        "#Saving it to the CSV\n",
        "combined_col.to_csv('Sentiment_Analysis_Dataset.csv', index=False)\n",
        "\n",
        "#Checking for null values\n",
        "print(combined_col.isnull().sum())\n",
        "\n",
        "#Building a list of stopwords\n",
        "stopwords = list(STOP_WORDS)\n",
        "\n",
        "#Defining the punctuations and parser\n",
        "punctuations = string.punctuation\n",
        "\n",
        "def parser(text):\n",
        "    return [word for word in text.lower().split() if word not in stopwords and word not in punctuations]\n",
        "\n",
        "#Creating a class for predictors\n",
        "class Predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [parser(review) for review in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "#Preparing the dataset\n",
        "X = combined_col['Review']\n",
        "y = combined_col['Label']\n",
        "\n",
        "#Splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#Creating a pipeline and fitting the data\n",
        "pipe_countvect = Pipeline([\n",
        "    ('cleaner', Predictors()),\n",
        "    ('vectorizer', TfidfVectorizer(tokenizer=lambda x: x, preprocessor=lambda x: x)),\n",
        "    ('classifier', LinearSVC())\n",
        "])\n",
        "\n",
        "pipe_countvect.fit(X_train, y_train)\n",
        "\n",
        "#Predicting with the test dataset\n",
        "predictions = pipe_countvect.predict(X_test)\n",
        "\n",
        "#Printing sample predictions\n",
        "for sample, pred in zip(X_test[:10], predictions[:10]):\n",
        "    print(sample, \"Prediction➔\", pred)\n",
        "\n",
        "#Determining accuracy for the test dataset\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f'Accuracy on test dataset: {accuracy:.2f}')\n",
        "\n",
        "#Calculating accuracy for the train dataset\n",
        "train_predictions = pipe_countvect.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, train_predictions)\n",
        "print(f'Accuracy on train dataset: {train_accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gnYHCxdoBEg",
        "outputId": "e44eccd7-5668-4929-d8f7-d70f4ff2a72f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review     0\n",
            "Label      0\n",
            "Company    0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It's close to my house, it's low-key, non-fancy, affordable prices, good food. Prediction➔ 1\n",
            "If you stay in Vegas you must get breakfast here at least once. Prediction➔ 0\n",
            "Let's start with all the problemsthe acting, especially from the lead professor, was very, very bad.   Prediction➔ 0\n",
            "It's too bad that everyone else involved didn't share Crowe's level of dedication to quality, for if they did, we'd have a far better film on our hands than this sub-par mess.   Prediction➔ 0\n",
            "i felt insulted and disrespected, how could you talk and judge another human being like that? Prediction➔ 0\n",
            "Yet Plantronincs continues to use the same flawed charger design. Prediction➔ 0\n",
            "Whatever prompted such a documentary is beyond me!   Prediction➔ 0\n",
            "Any grandmother can make a roasted chicken better than this one. Prediction➔ 1\n",
            "Do NOT buy if you want to use the holster. Prediction➔ 0\n",
            "I ordered this product first and was unhappy with it immediately. Prediction➔ 0\n",
            "Accuracy on test dataset: 0.77\n",
            "Accuracy on train dataset: 0.99\n"
          ]
        }
      ]
    }
  ]
}